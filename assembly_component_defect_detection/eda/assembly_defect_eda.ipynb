{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 드라이브 마운트"
      ],
      "metadata": {
        "id": "tHA_Bl2IyTXQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5cOJ-3Si0yk",
        "outputId": "6e74ecbf-6041-4d7b-e025-c6e3b6d4bca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 임포트"
      ],
      "metadata": {
        "id": "dfd8Pfp7yWhE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z--c93OvcWVG"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import shutil\n",
        "import time\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "wSrBE7-Pzj1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    drive_root = '/content/drive/MyDrive/의장공정/데이터/Validation'\n",
        "    original_data_path = os.path.join(drive_root, '원천데이터')\n",
        "    label_data_path = os.path.join(drive_root, '라벨링데이터')\n",
        "\n",
        "def load_and_analyze_data():\n",
        "    \"\"\"원천데이터와 라벨링데이터를 로드하고 분석합니다.\"\"\"\n",
        "    print(\"데이터 로딩 및 분석 중...\")\n",
        "\n",
        "    # 원천데이터 파일 목록\n",
        "    original_files = []\n",
        "    for root, dirs, files in os.walk(Config.original_data_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "                original_files.append(os.path.join(root, file))\n",
        "\n",
        "    # 라벨링데이터 파일 목록\n",
        "    label_files = []\n",
        "    for root, dirs, files in os.walk(Config.label_data_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.json'):\n",
        "                label_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"원천데이터 이미지 수: {len(original_files)}\")\n",
        "    print(f\"라벨링데이터 파일 수: {len(label_files)}\")\n",
        "\n",
        "    return original_files, label_files\n",
        "\n",
        "def analyze_label_structure(label_files, num_samples=5):\n",
        "    \"\"\"라벨링 데이터의 구조를 분석합니다.\"\"\"\n",
        "    print(f\"라벨링 데이터 구조 분석 중... (샘플 {num_samples}개)\")\n",
        "\n",
        "    for i, label_file in enumerate(label_files[:num_samples]):\n",
        "        print(f\"\\n--- 샘플 {i+1}: {os.path.basename(label_file)} ---\")\n",
        "        try:\n",
        "            with open(label_file, 'r', encoding='utf-8-sig') as f:\n",
        "                label_data = json.load(f)\n",
        "\n",
        "            print(\"JSON 구조:\")\n",
        "            print(json.dumps(label_data, ensure_ascii=False, indent=2)[:500] + \"...\")\n",
        "\n",
        "            # 주요 키들 확인\n",
        "            print(f\"주요 키들: {list(label_data.keys())}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "def analyze_class_distribution(paired_data):\n",
        "    \"\"\"클래스별 데이터 개수 분석\"\"\"\n",
        "    class_counts = {}\n",
        "    category_counts = {}\n",
        "    quality_counts = {}\n",
        "\n",
        "    for item in paired_data:\n",
        "        label = item['label']\n",
        "        category = item.get('category_name', 'unknown')\n",
        "        quality = item.get('quality', 'unknown')\n",
        "\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "        category_counts[category] = category_counts.get(category, 0) + 1\n",
        "        quality_counts[quality] = quality_counts.get(quality, 0) + 1\n",
        "\n",
        "    print(\"\\n=== 클래스별 데이터 개수 ===\")\n",
        "    for label, count in sorted(class_counts.items()):\n",
        "        print(f\"  {label}: {count}개\")\n",
        "\n",
        "    print(\"\\n=== 카테고리별 데이터 개수 ===\")\n",
        "    for category, count in sorted(category_counts.items()):\n",
        "        print(f\"  {category}: {count}개\")\n",
        "\n",
        "    print(\"\\n=== 품질별 데이터 개수 ===\")\n",
        "    for quality, count in sorted(quality_counts.items()):\n",
        "        print(f\"  {quality}: {count}개\")\n",
        "\n",
        "def analyze_file_structure():\n",
        "    \"\"\"현재 복사된 파일 개수 확인\"\"\"\n",
        "    dataset_dir = '/content/drive/MyDrive/의장공정/데이터/image_classification/dataset'\n",
        "    splits = ['train', 'valid', 'test']\n",
        "\n",
        "    print(\"=== 현재 복사된 파일 개수 확인 ===\")\n",
        "    total_files = 0\n",
        "\n",
        "    for split in splits:\n",
        "        split_dir = os.path.join(dataset_dir, split)\n",
        "\n",
        "        if os.path.exists(split_dir):\n",
        "            files = [f for f in os.listdir(split_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "            file_count = len(files)\n",
        "            total_files += file_count\n",
        "\n",
        "            print(f\"{split}: {file_count:,}개\")\n",
        "\n",
        "            # 첫 3개 파일명 확인\n",
        "            if files:\n",
        "                print(f\"  예시 파일명:\")\n",
        "                for i, file in enumerate(files[:3]):\n",
        "                    print(f\"    {file}\")\n",
        "            print()\n",
        "        else:\n",
        "            print(f\"{split}: 폴더 없음\")\n",
        "\n",
        "    print(f\"전체 복사된 파일: {total_files:,}개\")\n",
        "    return total_files\n",
        "\n",
        "def create_image_label_pairs(original_files, label_files):\n",
        "    \"\"\"이미지와 라벨 파일을 매칭하여 데이터셋을 생성합니다.\"\"\"\n",
        "    print(\"이미지-라벨 매칭 중...\")\n",
        "\n",
        "    # 먼저 라벨 데이터 구조 분석\n",
        "    analyze_label_structure(label_files)\n",
        "\n",
        "    # 1000개씩 나누어서 처리\n",
        "    batch_size = 1000\n",
        "    total_files = len(original_files)\n",
        "    all_paired_data = []\n",
        "    all_labels_set = set()\n",
        "\n",
        "    # 라벨 딕셔너리는 미리 생성\n",
        "    label_dict = {}\n",
        "    for label_file in label_files:\n",
        "        base_name = os.path.splitext(os.path.basename(label_file))[0]\n",
        "        label_dict[base_name] = label_file\n",
        "\n",
        "    print(f\"라벨 딕셔너리 생성 완료: {len(label_dict)}개\")\n",
        "\n",
        "    # 배치별로 처리\n",
        "    for start_idx in range(0, total_files, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, total_files)\n",
        "        batch_files = original_files[start_idx:end_idx]\n",
        "\n",
        "        print(f\"배치 처리 중: {start_idx}-{end_idx} ({start_idx/total_files*100:.1f}%)\")\n",
        "\n",
        "        # 이 배치만 처리\n",
        "        batch_paired_data = []\n",
        "        for img_file in batch_files:\n",
        "            img_base_name = os.path.splitext(os.path.basename(img_file))[0]\n",
        "\n",
        "            if img_base_name in label_dict:\n",
        "                try:\n",
        "                    with open(label_dict[img_base_name], 'r', encoding='utf-8-sig') as f:\n",
        "                        label_data = json.load(f)\n",
        "\n",
        "                    # JSON 구조에 맞는 라벨 추출\n",
        "                    label = None\n",
        "                    category_name = None\n",
        "                    quality = None\n",
        "\n",
        "                    # categories 딕셔너리 생성\n",
        "                    categories_dict = {}\n",
        "                    if 'categories' in label_data:\n",
        "                        for cat in label_data['categories']:\n",
        "                            categories_dict[cat['id']] = cat['name']\n",
        "\n",
        "                    # annotations에서 정보 추출\n",
        "                    if 'annotations' in label_data and len(label_data['annotations']) > 0:\n",
        "                        annotation = label_data['annotations'][0]\n",
        "\n",
        "                        if 'category_id' in annotation and annotation['category_id'] in categories_dict:\n",
        "                            category_name = categories_dict[annotation['category_id']]\n",
        "\n",
        "                        if 'attributes' in annotation and 'quality' in annotation['attributes']:\n",
        "                            quality = annotation['attributes']['quality']\n",
        "\n",
        "                    # 라벨 생성\n",
        "                    if category_name and quality:\n",
        "                        label = f\"{category_name}_{quality}\"\n",
        "                    elif category_name:\n",
        "                        label = category_name\n",
        "                    else:\n",
        "                        # 폴더 경로에서 라벨 추출\n",
        "                        folder_parts = img_file.split(os.sep)\n",
        "                        if len(folder_parts) >= 3:\n",
        "                            label = f\"{folder_parts[-3]}_{folder_parts[-2]}\"\n",
        "                        else:\n",
        "                            label = 'unknown'\n",
        "\n",
        "                    batch_paired_data.append({\n",
        "                        'image_path': img_file,\n",
        "                        'label_path': label_dict[img_base_name],\n",
        "                        'label': str(label),\n",
        "                        'image_name': os.path.basename(img_file),\n",
        "                        'category_name': category_name,\n",
        "                        'quality': quality\n",
        "                    })\n",
        "                    all_labels_set.add(str(label))\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  오류 건너뜀: {e}\")\n",
        "\n",
        "        all_paired_data.extend(batch_paired_data)\n",
        "        print(f\"  이 배치 결과: {len(batch_paired_data)}개 매칭\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        del batch_paired_data\n",
        "\n",
        "    print(f\"\\n매칭 완료!\")\n",
        "    print(f\"매칭된 이미지-라벨 쌍: {len(all_paired_data)}\")\n",
        "    print(f\"발견된 클래스 수: {len(all_labels_set)}\")\n",
        "\n",
        "    # 클래스별 분포 분석\n",
        "    analyze_class_distribution(all_paired_data)\n",
        "\n",
        "    return all_paired_data, sorted(list(all_labels_set))\n",
        "\n",
        "# 실행 함수\n",
        "def run_eda():\n",
        "    \"\"\"전체 EDA 실행\"\"\"\n",
        "    print(\"=== 이미지 분류 EDA 시작 ===\")\n",
        "\n",
        "    # 1. 데이터 로드 및 분석\n",
        "    original_files, label_files = load_and_analyze_data()\n",
        "\n",
        "    # 2. 이미지-라벨 매칭\n",
        "    paired_data, class_names = create_image_label_pairs(original_files, label_files)\n",
        "\n",
        "    # 3. 파일 구조 분석\n",
        "    analyze_file_structure()\n",
        "\n",
        "    print(\"\\n=== EDA 완료 ===\")\n",
        "    return paired_data, class_names\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    paired_data, class_names = run_eda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "OsGcdSTRyu80",
        "outputId": "4865d3ce-c74a-4f29-92c1-accba1f6ceb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 이미지 분류 EDA 시작 ===\n",
            "데이터 로딩 및 분석 중...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4136426.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;31m# 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mpaired_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_eda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4136426.py\u001b[0m in \u001b[0;36mrun_eda\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# 1. 데이터 로드 및 분석\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0moriginal_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_analyze_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# 2. 이미지-라벨 매칭\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4136426.py\u001b[0m in \u001b[0;36mload_and_analyze_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 원천데이터 파일 목록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moriginal_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.bmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 분류 EDA (탐색적 데이터 분석) 코드\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class Config:\n",
        "    drive_root = '/content/drive/MyDrive/의장공정/데이터/Validation'\n",
        "    original_data_path = os.path.join(drive_root, '원천데이터')\n",
        "    label_data_path = os.path.join(drive_root, '라벨링데이터')\n",
        "\n",
        "def load_and_analyze_data():\n",
        "    \"\"\"원천데이터와 라벨링데이터를 로드하고 분석합니다.\"\"\"\n",
        "    print(\"데이터 로딩 및 분석 중...\")\n",
        "\n",
        "    # 원천데이터 파일 목록\n",
        "    original_files = []\n",
        "    for root, dirs, files in os.walk(Config.original_data_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "                original_files.append(os.path.join(root, file))\n",
        "\n",
        "    # 라벨링데이터 파일 목록\n",
        "    label_files = []\n",
        "    for root, dirs, files in os.walk(Config.label_data_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.json'):\n",
        "                label_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"원천데이터 이미지 수: {len(original_files)}\")\n",
        "    print(f\"라벨링데이터 파일 수: {len(label_files)}\")\n",
        "\n",
        "    return original_files, label_files\n",
        "\n",
        "def analyze_label_structure(label_files, num_samples=5):\n",
        "    \"\"\"라벨링 데이터의 구조를 분석합니다.\"\"\"\n",
        "    print(f\"라벨링 데이터 구조 분석 중... (샘플 {num_samples}개)\")\n",
        "\n",
        "    for i, label_file in enumerate(label_files[:num_samples]):\n",
        "        print(f\"\\n--- 샘플 {i+1}: {os.path.basename(label_file)} ---\")\n",
        "        try:\n",
        "            with open(label_file, 'r', encoding='utf-8-sig') as f:\n",
        "                label_data = json.load(f)\n",
        "\n",
        "            print(\"JSON 구조:\")\n",
        "            print(json.dumps(label_data, ensure_ascii=False, indent=2)[:500] + \"...\")\n",
        "\n",
        "            # 주요 키들 확인\n",
        "            print(f\"주요 키들: {list(label_data.keys())}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "def analyze_class_distribution(paired_data):\n",
        "    \"\"\"클래스별 데이터 개수 분석\"\"\"\n",
        "    class_counts = {}\n",
        "    category_counts = {}\n",
        "    quality_counts = {}\n",
        "\n",
        "    for item in paired_data:\n",
        "        label = item['label']\n",
        "        category = item.get('category_name', 'unknown')\n",
        "        quality = item.get('quality', 'unknown')\n",
        "\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "        category_counts[category] = category_counts.get(category, 0) + 1\n",
        "        quality_counts[quality] = quality_counts.get(quality, 0) + 1\n",
        "\n",
        "    print(\"\\n=== 클래스별 데이터 개수 ===\")\n",
        "    for label, count in sorted(class_counts.items()):\n",
        "        print(f\"  {label}: {count}개\")\n",
        "\n",
        "    print(\"\\n=== 카테고리별 데이터 개수 ===\")\n",
        "    for category, count in sorted(category_counts.items()):\n",
        "        print(f\"  {category}: {count}개\")\n",
        "\n",
        "    print(\"\\n=== 품질별 데이터 개수 ===\")\n",
        "    for quality, count in sorted(quality_counts.items()):\n",
        "        print(f\"  {quality}: {count}개\")\n",
        "\n",
        "def analyze_file_structure():\n",
        "    \"\"\"현재 복사된 파일 개수 확인\"\"\"\n",
        "    dataset_dir = '/content/drive/MyDrive/의장공정/데이터/image_classification/dataset'\n",
        "    splits = ['train', 'valid', 'test']\n",
        "\n",
        "    print(\"=== 현재 복사된 파일 개수 확인 ===\")\n",
        "    total_files = 0\n",
        "\n",
        "    for split in splits:\n",
        "        split_dir = os.path.join(dataset_dir, split)\n",
        "\n",
        "        if os.path.exists(split_dir):\n",
        "            files = [f for f in os.listdir(split_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "            file_count = len(files)\n",
        "            total_files += file_count\n",
        "\n",
        "            print(f\"{split}: {file_count:,}개\")\n",
        "\n",
        "            # 첫 3개 파일명 확인\n",
        "            if files:\n",
        "                print(f\"  예시 파일명:\")\n",
        "                for i, file in enumerate(files[:3]):\n",
        "                    print(f\"    {file}\")\n",
        "            print()\n",
        "        else:\n",
        "            print(f\"{split}: 폴더 없음\")\n",
        "\n",
        "    print(f\"전체 복사된 파일: {total_files:,}개\")\n",
        "    return total_files\n",
        "\n",
        "def create_image_label_pairs(original_files, label_files):\n",
        "    \"\"\"이미지와 라벨 파일을 매칭하여 데이터셋을 생성합니다.\"\"\"\n",
        "    print(\"이미지-라벨 매칭 중...\")\n",
        "\n",
        "    # 먼저 라벨 데이터 구조 분석\n",
        "    analyze_label_structure(label_files)\n",
        "\n",
        "    # 1000개씩 나누어서 처리\n",
        "    batch_size = 1000\n",
        "    total_files = len(original_files)\n",
        "    all_paired_data = []\n",
        "    all_labels_set = set()\n",
        "\n",
        "    # 라벨 딕셔너리는 미리 생성\n",
        "    label_dict = {}\n",
        "    for label_file in label_files:\n",
        "        base_name = os.path.splitext(os.path.basename(label_file))[0]\n",
        "        label_dict[base_name] = label_file\n",
        "\n",
        "    print(f\"라벨 딕셔너리 생성 완료: {len(label_dict)}개\")\n",
        "\n",
        "    # 배치별로 처리\n",
        "    for start_idx in range(0, total_files, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, total_files)\n",
        "        batch_files = original_files[start_idx:end_idx]\n",
        "\n",
        "        print(f\"배치 처리 중: {start_idx}-{end_idx} ({start_idx/total_files*100:.1f}%)\")\n",
        "\n",
        "        # 이 배치만 처리\n",
        "        batch_paired_data = []\n",
        "        for img_file in batch_files:\n",
        "            img_base_name = os.path.splitext(os.path.basename(img_file))[0]\n",
        "\n",
        "            if img_base_name in label_dict:\n",
        "                try:\n",
        "                    with open(label_dict[img_base_name], 'r', encoding='utf-8-sig') as f:\n",
        "                        label_data = json.load(f)\n",
        "\n",
        "                    # JSON 구조에 맞는 라벨 추출\n",
        "                    label = None\n",
        "                    category_name = None\n",
        "                    quality = None\n",
        "\n",
        "                    # categories 딕셔너리 생성\n",
        "                    categories_dict = {}\n",
        "                    if 'categories' in label_data:\n",
        "                        for cat in label_data['categories']:\n",
        "                            categories_dict[cat['id']] = cat['name']\n",
        "\n",
        "                    # annotations에서 정보 추출\n",
        "                    if 'annotations' in label_data and len(label_data['annotations']) > 0:\n",
        "                        annotation = label_data['annotations'][0]\n",
        "\n",
        "                        if 'category_id' in annotation and annotation['category_id'] in categories_dict:\n",
        "                            category_name = categories_dict[annotation['category_id']]\n",
        "\n",
        "                        if 'attributes' in annotation and 'quality' in annotation['attributes']:\n",
        "                            quality = annotation['attributes']['quality']\n",
        "\n",
        "                    # 라벨 생성\n",
        "                    if category_name and quality:\n",
        "                        label = f\"{category_name}_{quality}\"\n",
        "                    elif category_name:\n",
        "                        label = category_name\n",
        "                    else:\n",
        "                        # 폴더 경로에서 라벨 추출\n",
        "                        folder_parts = img_file.split(os.sep)\n",
        "                        if len(folder_parts) >= 3:\n",
        "                            label = f\"{folder_parts[-3]}_{folder_parts[-2]}\"\n",
        "                        else:\n",
        "                            label = 'unknown'\n",
        "\n",
        "                    batch_paired_data.append({\n",
        "                        'image_path': img_file,\n",
        "                        'label_path': label_dict[img_base_name],\n",
        "                        'label': str(label),\n",
        "                        'image_name': os.path.basename(img_file),\n",
        "                        'category_name': category_name,\n",
        "                        'quality': quality\n",
        "                    })\n",
        "                    all_labels_set.add(str(label))\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  오류 건너뜀: {e}\")\n",
        "\n",
        "        all_paired_data.extend(batch_paired_data)\n",
        "        print(f\"  이 배치 결과: {len(batch_paired_data)}개 매칭\")\n",
        "\n",
        "        # 메모리 정리\n",
        "        del batch_paired_data\n",
        "\n",
        "    print(f\"\\n매칭 완료!\")\n",
        "    print(f\"매칭된 이미지-라벨 쌍: {len(all_paired_data)}\")\n",
        "    print(f\"발견된 클래스 수: {len(all_labels_set)}\")\n",
        "\n",
        "    # 클래스별 분포 분석\n",
        "    analyze_class_distribution(all_paired_data)\n",
        "\n",
        "    return all_paired_data, sorted(list(all_labels_set))\n",
        "\n",
        "# 실행 함수\n",
        "def run_eda():\n",
        "    \"\"\"전체 EDA 실행\"\"\"\n",
        "    print(\"=== 이미지 분류 EDA 시작 ===\")\n",
        "\n",
        "    # 1. 데이터 로드 및 분석\n",
        "    original_files, label_files = load_and_analyze_data()\n",
        "\n",
        "    # 2. 이미지-라벨 매칭\n",
        "    paired_data, class_names = create_image_label_pairs(original_files, label_files)\n",
        "\n",
        "    # 3. 파일 구조 분석\n",
        "    analyze_file_structure()\n",
        "\n",
        "    print(\"\\n=== EDA 완료 ===\")\n",
        "    return paired_data, class_names\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    paired_data, class_names = run_eda()"
      ],
      "metadata": {
        "id": "7KZwA2Y_yjlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA 결과"
      ],
      "metadata": {
        "id": "sZLbLwIb0WKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩 및 분석 중...\n",
        "# 원천데이터 이미지 수: 21553\n",
        "# 라벨링데이터 파일 수: 21553\n",
        "# 이미지-라벨 매칭 중...\n",
        "# 라벨링 데이터 구조 분석 중... (샘플 5개)\n",
        "\n",
        "# --- 샘플 1: 204_101_20_1bace470-0fad-4b08-a0f2-f399063a9f6f.json ---\n",
        "# JSON 구조:\n",
        "# {\n",
        "#   \"info\": {\n",
        "#     \"contributor\": \"미래아이티컨소시엄\",\n",
        "#     \"date_created\": \"2021-12-02 08:54:24.241591\",\n",
        "#     \"name\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"description\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"version\": \"1.0\",\n",
        "#     \"url\": \"miraeit.net/\"\n",
        "#   },\n",
        "#   \"images\": [\n",
        "#     {\n",
        "#       \"license\": 1,\n",
        "#       \"file_name\": \"204_101_20_1bace470-0fad-4b08-a0f2-f399063a9f6f.jpg\",\n",
        "#       \"width\": 4000,\n",
        "#       \"date_captured\": \"2021-11-25 13:57:21\",\n",
        "#       \"id\": 1,\n",
        "#       \"height\": 3000\n",
        "#     }\n",
        "#   ],\n",
        "#   \"licenses\": [\n",
        "#     {\n",
        "#       \"name\": \"CC BY-N...\n",
        "# 주요 키들: ['info', 'images', 'licenses', 'categories', 'annotations']\n",
        "\n",
        "# --- 샘플 2: 204_101_20_1bf6a4a7-ef91-4efb-aee4-965af8326c49.json ---\n",
        "# JSON 구조:\n",
        "# {\n",
        "#   \"info\": {\n",
        "#     \"contributor\": \"미래아이티컨소시엄\",\n",
        "#     \"date_created\": \"2021-12-24 13:52:22.338968\",\n",
        "#     \"name\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"description\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"version\": \"1.0\",\n",
        "#     \"url\": \"miraeit.net/\"\n",
        "#   },\n",
        "#   \"images\": [\n",
        "#     {\n",
        "#       \"license\": 1,\n",
        "#       \"file_name\": \"204_101_20_1bf6a4a7-ef91-4efb-aee4-965af8326c49.JPG\",\n",
        "#       \"width\": 4032,\n",
        "#       \"date_captured\": \"2021-12-15 21:23:29\",\n",
        "#       \"id\": 1,\n",
        "#       \"height\": 2268\n",
        "#     }\n",
        "#   ],\n",
        "#   \"licenses\": [\n",
        "#     {\n",
        "#       \"name\": \"CC BY-N...\n",
        "# 주요 키들: ['info', 'images', 'licenses', 'categories', 'annotations']\n",
        "\n",
        "# --- 샘플 3: 204_101_20_1c65599f-3bc1-4297-9179-fc6f5fb8c0ea.json ---\n",
        "# JSON 구조:\n",
        "# {\n",
        "#   \"info\": {\n",
        "#     \"contributor\": \"미래아이티컨소시엄\",\n",
        "#     \"date_created\": \"2021-12-24 15:34:33.045516\",\n",
        "#     \"name\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"description\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"version\": \"1.0\",\n",
        "#     \"url\": \"miraeit.net/\"\n",
        "#   },\n",
        "#   \"images\": [\n",
        "#     {\n",
        "#       \"license\": 1,\n",
        "#       \"file_name\": \"204_101_20_1c65599f-3bc1-4297-9179-fc6f5fb8c0ea.jpg\",\n",
        "#       \"width\": 1920,\n",
        "#       \"date_captured\": \"2021-12-14 12:12:41\",\n",
        "#       \"id\": 1,\n",
        "#       \"height\": 1080\n",
        "#     }\n",
        "#   ],\n",
        "#   \"licenses\": [\n",
        "#     {\n",
        "#       \"name\": \"CC BY-N...\n",
        "# 주요 키들: ['info', 'images', 'licenses', 'categories', 'annotations']\n",
        "\n",
        "# --- 샘플 4: 204_101_20_1cd1e82c-0736-4442-b377-aafd5091528c.json ---\n",
        "# JSON 구조:\n",
        "# {\n",
        "#   \"info\": {\n",
        "#     \"contributor\": \"미래아이티컨소시엄\",\n",
        "#     \"date_created\": \"2021-12-20 15:54:00.28187\",\n",
        "#     \"name\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"description\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"version\": \"1.0\",\n",
        "#     \"url\": \"miraeit.net/\"\n",
        "#   },\n",
        "#   \"images\": [\n",
        "#     {\n",
        "#       \"license\": 1,\n",
        "#       \"file_name\": \"204_101_20_1cd1e82c-0736-4442-b377-aafd5091528c.jpg\",\n",
        "#       \"width\": 4224,\n",
        "#       \"date_captured\": \"2021-12-14 11:43:57\",\n",
        "#       \"id\": 1,\n",
        "#       \"height\": 2376\n",
        "#     }\n",
        "#   ],\n",
        "#   \"licenses\": [\n",
        "#     {\n",
        "#       \"name\": \"CC BY-NC...\n",
        "# 주요 키들: ['info', 'images', 'licenses', 'categories', 'annotations']\n",
        "\n",
        "# --- 샘플 5: 204_101_20_1cf0b04f-72b3-4b7d-8702-14eddef8996b.json ---\n",
        "# JSON 구조:\n",
        "# {\n",
        "#   \"info\": {\n",
        "#     \"contributor\": \"미래아이티컨소시엄\",\n",
        "#     \"date_created\": \"2021-12-25 16:48:45.309279\",\n",
        "#     \"name\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"description\": \"부품 품질 검사 영상 데이터(자동차)\",\n",
        "#     \"version\": \"1.0\",\n",
        "#     \"url\": \"miraeit.net/\"\n",
        "#   },\n",
        "#   \"images\": [\n",
        "#     {\n",
        "#       \"license\": 1,\n",
        "#       \"file_name\": \"204_101_20_1cf0b04f-72b3-4b7d-8702-14eddef8996b.jpg\",\n",
        "#       \"width\": 4624,\n",
        "#       \"date_captured\": \"2021-12-16 14:56:20\",\n",
        "#       \"id\": 1,\n",
        "#       \"height\": 2084\n",
        "#     }\n",
        "#   ],\n",
        "#   \"licenses\": [\n",
        "#     {\n",
        "#       \"name\": \"CC BY-N...\n",
        "# 주요 키들: ['info', 'images', 'licenses', 'categories', 'annotations']\n",
        "\n",
        "# ==================================================\n",
        "# 라벨 딕셔너리 생성 완료: 21553개\n",
        "# 배치 처리 중: 0-1000 (0.0%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 1000-2000 (4.6%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 2000-3000 (9.3%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 3000-4000 (13.9%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 4000-5000 (18.6%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 5000-6000 (23.2%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 6000-7000 (27.8%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 7000-8000 (32.5%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 8000-9000 (37.1%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 9000-10000 (41.8%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 10000-11000 (46.4%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 11000-12000 (51.0%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 12000-13000 (55.7%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 13000-14000 (60.3%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 14000-15000 (65.0%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 15000-16000 (69.6%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 16000-17000 (74.2%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 17000-18000 (78.9%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 18000-19000 (83.5%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 19000-20000 (88.2%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 20000-21000 (92.8%)\n",
        "#   이 배치 결과: 1000개 매칭\n",
        "# 배치 처리 중: 21000-21553 (97.4%)\n",
        "#   이 배치 결과: 553개 매칭\n",
        "\n",
        "# 매칭 완료!\n",
        "# 매칭된 이미지-라벨 쌍: 21553\n",
        "# 발견된 클래스 수: 24\n",
        "\n",
        "# === 클래스별 데이터 개수 ===\n",
        "#   고정 불량_불량품: 757개\n",
        "#   고정 불량_양품: 603개\n",
        "#   고정핀 불량_불량품: 651개\n",
        "#   고정핀 불량_양품: 644개\n",
        "#   단차_불량품: 2714개\n",
        "#   단차_양품: 2718개\n",
        "#   스크래치_불량품: 1752개\n",
        "#   스크래치_양품: 895개\n",
        "#   실링 불량_불량품: 423개\n",
        "#   실링 불량_양품: 214개\n",
        "#   연계 불량_불량품: 636개\n",
        "#   연계 불량_양품: 618개\n",
        "#   외관 손상_불량품: 1152개\n",
        "#   외관 손상_양품: 1060개\n",
        "#   유격 불량_불량품: 982개\n",
        "#   유격 불량_양품: 630개\n",
        "#   장착 불량_불량품: 645개\n",
        "#   장착 불량_양품: 650개\n",
        "#   체결 불량_불량품: 1337개\n",
        "#   체결 불량_양품: 587개\n",
        "#   헤밍 불량_불량품: 543개\n",
        "#   헤밍 불량_양품: 506개\n",
        "#   홀 변형_불량품: 401개\n",
        "#   홀 변형_양품: 435개\n",
        "\n",
        "# === 카테고리별 데이터 개수 ===\n",
        "#   고정 불량: 1360개\n",
        "#   고정핀 불량: 1295개\n",
        "#   단차: 5432개\n",
        "#   스크래치: 2647개\n",
        "#   실링 불량: 637개\n",
        "#   연계 불량: 1254개\n",
        "#   외관 손상: 2212개\n",
        "#   유격 불량: 1612개\n",
        "#   장착 불량: 1295개\n",
        "#   체결 불량: 1924개\n",
        "#   헤밍 불량: 1049개\n",
        "#   홀 변형: 836개\n",
        "\n",
        "# === 품질별 데이터 개수 ===\n",
        "#   불량품: 11993개\n",
        "#   양품: 9560개\n",
        "# 데이터셋 분할 및 복사 중...\n",
        "# 클래스 고정 불량_불량품: train=529, valid=114, test=114\n",
        "# 클래스 고정 불량_양품: train=422, valid=90, test=91\n",
        "# 클래스 고정핀 불량_불량품: train=455, valid=98, test=98\n",
        "# 클래스 고정핀 불량_양품: train=450, valid=97, test=97\n",
        "# 클래스 단차_불량품: train=1899, valid=407, test=408\n",
        "# 클래스 단차_양품: train=1902, valid=408, test=408\n",
        "# 클래스 스크래치_불량품: train=1226, valid=263, test=263\n",
        "# 클래스 스크래치_양품: train=626, valid=134, test=135\n",
        "# 클래스 실링 불량_불량품: train=296, valid=63, test=64\n",
        "# 클래스 실링 불량_양품: train=149, valid=32, test=33\n",
        "# 클래스 연계 불량_불량품: train=445, valid=95, test=96\n",
        "# 클래스 연계 불량_양품: train=432, valid=93, test=93\n",
        "# 클래스 외관 손상_불량품: train=806, valid=173, test=173\n",
        "# 클래스 외관 손상_양품: train=742, valid=159, test=159\n",
        "# 클래스 유격 불량_불량품: train=687, valid=147, test=148\n",
        "# 클래스 유격 불량_양품: train=441, valid=94, test=95\n",
        "# 클래스 장착 불량_불량품: train=451, valid=97, test=97\n",
        "# 클래스 장착 불량_양품: train=455, valid=97, test=98\n",
        "# 클래스 체결 불량_불량품: train=935, valid=201, test=201\n",
        "# 클래스 체결 불량_양품: train=410, valid=88, test=89\n",
        "# 클래스 헤밍 불량_불량품: train=380, valid=81, test=82\n",
        "# 클래스 헤밍 불량_양품: train=354, valid=76, test=76\n",
        "# 클래스 홀 변형_불량품: train=280, valid=60, test=61\n",
        "# 클래스 홀 변형_양품: train=304, valid=65, test=66\n",
        "\n",
        "# train 데이터 복사 중... (15076개)\n",
        "\n",
        "# valid 데이터 복사 중... (3232개)\n",
        "\n",
        "# test 데이터 복사 중... (3245개)\n",
        "# 훈련 데이터가 없습니다. 종료합니다."
      ],
      "metadata": {
        "id": "yHawFK820G1n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tC9NW-Wy0UnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
